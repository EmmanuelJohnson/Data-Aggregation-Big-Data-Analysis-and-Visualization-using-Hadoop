The robot future is here. From automated personal assistants, like Siri and Alexa, to security bots, self-driving cars, algorithms and holograms, robots and other artificially intelligent machines are already embedded in our daily lives.
What day-to-day interactions do you have with robots? How do you feel about the presence of artificial intelligence in your personal life, community or society at large? Why?
In “Why Do We Hurt Robots?,” Jonah Engel Bromwich writes about a wave of violence against intelligent machines:
A hitchhiking robot was beheaded in Philadelphia. A security robot was punched to the ground in Silicon Valley. Another security bot, in San Francisco, was covered in a tarp and smeared with barbecue sauce.
Why do people lash out at robots, particularly those that are built to resemble humans? It’s a global phenomenon. In a mall in Osaka, Japan, three boys beat a humanoid robot with all their strength. In Moscow, a man attacked a teaching robot named Alantim with a baseball bat, kicking it to the ground, while the robot pleaded for help.
Why do we act this way? Are we secretly terrified that robots will take our jobs? Upend our societies? Control our every move with their ever-expanding capabilities and air of quiet malice?
Quite possibly. The specter of insurrection is embedded in the word “robot” itself. It was first used to refer to automatons by the Czech playwright, Karel Capek, who repurposed a word that had referred to a system of indentured servitude or serfdom. The feudal fear of peasant revolt was transplanted to mechanical servants, and worries of a robot uprising have lingered ever since. …
But Agnieszka Wykowska, a cognitive neuroscientist, researcher at the Italian Institute of Technology and the editor in chief of the International Journal of Social Robotics, said that while human antagonism toward robots has different forms and motivations, it often resembles the ways that humans hurt each other. Robot abuse, she said, might stem from the tribal psychology of insiders and outsiders.
“You have an agent, the robot, that is in a different category than humans,” she said. “So you probably very easily engage in this psychological mechanism of social ostracism because it’s an out-group member. That’s something to discuss: the dehumanization of robots even though they’re not humans.”
Paradoxically, our tendency to dehumanize robots comes from the instinct to anthropomorphize them. William Santana Li, the chief executive of Knightscope, the largest provider of security robots in the United States (two of which were battered in San Francisco), said that while he avoids treating his products as if they were sentient beings, his clients seem unable to help themselves. “Our clients, a significant majority, end up naming the machines themselves,” he said. “There’s Holmes and Watson, there’s Rosie, there’s Steve, there’s CB2, there’s CX3PO.”
Students, read the entire article, then tell us:
— Have you ever felt anger, fear or hatred toward robots, like that described in the article? Have you ever witnessed someone abuse, or have you yourself abused, a machine?
— The article gives several explanations for why humans hurt robots. Which are the most convincing to you and why? What theories do you have for why humans may mistreat machines?
— How do you feel about an automated future? Do you fear countless professions becoming obsolete, the merging of humans and machines, an age of artificial intimacy or a potential robot uprising? Or are you excited about all the possibilities such a future could hold? Explain why you feel the way you do.
— Some say that anthropomorphizing robots — for example, giving them names and getting to know them — encourages humans to be kinder to them. Do you think we should treat robots like people? What are the benefits of doing so? What are the dangers?
— How do you think relationships between robots and humans should be governed? Should people be imprisoned for robot abuse? Should artificially intelligent machines be protected under the law in the same way we are? Where do we draw the line between human and machine — if we draw one at all?
Students 13 and older are invited to comment. All comments are moderated by the Learning Network staff, but please keep in mind that once your comment is accepted, it will be made public.
